Target:
4th day/30
----------
1)product building
2)java,springboot, hibernate normal job learning
3)applying remote job
4)ds & algorithms
5)Elm,Erlong, Elixir jobs remote
remoteok, workremotely,hasjob,indeed,naukri,angel.co
6)commit learning to github.com
gathering,tutorial,practicing
7)docker ruby on rails with git
git repo, secret with environment, dockerfile, run locally
8)kafka,couchdb, casandra
go,javaa
9)ruby on rails blog tutorial
10)blogbuiltwith(ror,go,python django,elixir,node.js)
11)elastic search
----------
learn one arabic word every day

1)Applying remote job
Erlong jobs
1)google search Erlong remote jobs
2)update resume in naukri, linkedin with 
Erlong, Elixir,Go
done in naukri
---
weworkremotely site
github jobs
---
https://jobmote.com/jobs/7471-senior-developer-ruby-rails-elm
Our code is a mixture of Ruby, Elm, Javascript, and a dash of Clojure. Additionally, we have a strong interest in functional programming languages like Haskell, OCaml, Elixir, and Idris. We're also using Rails, React, Postgresql, S3, Redis, Memcached, Docker, Nomad, Terraform, and more. While these are the tools we're currently using, you don't need to have previous experience with them. We know that good developers are capable of quickly picking up new languages and tools.

---
functional programming language
Haskell, OCaml, Elixir, Idris

other technologies
Nomad, Terraform, Cloure
---
https://jobs.github.com/positions/6bf2b51c-af87-11e7-8f77-fe95300449e5
http://careers.citrusbyte.com/apply/tPTZOv/Experienced-Backend-Engineer
---
write article on technology
---
Write some code, that will flatten an array of arbitrarily nested arrays of integers into a flat array of integers. e.g. [[1,2,[3]],4] -> [1,2,3,4]. 

Your solution should be a link to a gist on gist.github.com with your implementation.

When writing this code, you can use any language you're comfortable with. The code must be well tested and documented if necessary, and in general please treat the quality of the code as if it was ready to ship to production.

Try to avoid using language defined methods like Ruby's Array#flatten.
---
https://apidock.com/ruby/Array/flatten
---
run ruby online

http://rextester.com/l/ruby_online_compiler
https://repl.it/languages
http://rubyfiddle.com/
---
iterating ruby
--
https://code-maven.com/for-loop-in-ruby
ruby
names = ['Foo', 'Bar', 'Baz']
 
puts names
puts
 
 
names.each { |item|
    puts item
}
puts
 
names.each do |item|
    puts item
end
--
arry.kind_of?(Array)
arr.is_a?

---
https://ruby-doc.org/core-2.2.0/Array.html
---
applied hellosign
---
hacker in residence
startup studio
---
https://www.simplyhired.com/job/7TzKuWs3hWW5_KftQ6UzqFBychl0Zx0dQ-8OPxdpuHlNWwASAqM_hw
---
Telnyx
Elixir Engineer
Product Engineering
Chicago, IL, United States
About Telnyx
Telnyx is building the global telco of the future. We have deployed an international private software-defined network, with multiple tier-1 interconnects, leveraging all major cloud service providers to deliver a voice and messaging solution with carrier-grade reliability. We sell our services in a totally automated fashion, allowing our users to programmatically scale their voice and messaging on-demand.
In addition to providing service and software in major North American and European markets, we are expanding to Asia and are developing a wireless product that will provide licensed spectrum access to our infrastructure.
Telnyx has seventy employees (70% engineers) between our Chicago, IL office, Dublin, Ireland office and remote team. We have actual revenue traction, meaningful sequential monthly growth, and a massive addressable market.

Joining Our Team
At Telnyx, we’re working to globally democratize access to real-time communications over the internet. We’re building a future where voice, messaging, and wireless services can act as building blocks to facilitate high-fidelity, secure, and modern modes of communication.
No matter where you're based, or which team you work on, you’ll be part of a group of people working together to build solutions to mission-critical problems and a company that values the very best ideas. People rely on our products to communicate daily, which means they rely on us to build things with a high degree of resiliency and reliability.

The Role
As an Elixir Engineer at Telnyx, you will deploy groundbreaking applications to solve our customers’ hardest problems. Projects often start with a nebulous question and our Engineers lead the way in developing a solution, from high-level system design and prototyping to application development and data integration. As a Telnyx software engineer, you leverage everything around you: Telnyx products, open source technologies, and anything you and your team can build to drive real impact.
 
You work with users around the globe, where you help our customers by solving their communications challenges. Each mission presents different challenges, from the regulatory environment to the nature of the data to the user population. You will work to accommodate all aspects of an environment to drive real technical outcomes.

In this role, you will:
Build Elixir products for the delivery of mission-critical global communications. These products are latency sensitive and must handle data at scale, all while maintaining an intuitive user experience.
Create tools to automate critical aspects of production systems.

What we value:
Strong engineering background, preferred in fields such as Computer Science, Mathematics, Software Engineering, Physics.
3+ years of professional software development experience with either Ruby or a functional programming language (Clojure, Erlang, etc).
Demonstrated ability to continuously learn, work independently, and make decisions with minimal supervision. You understand that making mistakes means you’re learning, and you actively seek opportunities to grow and develop.
You want to work on software that is changing the world and you're passionate about creating intuitive, scalable products that magnify the analytical capabilities of our users. 
Experience building and operating scalable infrastructure software or distributed systems.
Experience with large-scale production databases and major cloud services.
Familiarity with micro-service architectures.
Highly proficient in a Linux environment. 
Experience with PostgreSQL.
Experience working with message queues (RabbitMQ).
Unit testing (we don’t do TDD, but we like coverage - a lot).

Technologies we use
A variety of languages including Python, Java, Elixir, Scala, Go, Angular, and React.
Open-source technologies like Cassandra, Spark, and ElasticSearch.
Industry-standard build tooling, including Docker, Consul, Jenkins, Ansible, and Github.

Our Guiding Principles
We wrote these principles to be actionable, to inform decision-making and to provide a sense of what’s important and what’s right. We live our values every day. They guide how we hire, train, measure and reward each other.

Stay gritty
Do more with less. We are creative problem solvers that always use constraints to our advantage.

Leverage the experience of others
Avoid unnecessary detours by learning from the mistakes and successes of others. Those who do not learn from history are destined to repeat it.

Improve continually
Perfection is the enemy of progress. Always ask “why.” Think big, start small, collect data, and iterate quickly.

Work together
Seek exponential gains in our work by improving the lives of colleagues and customers.

Practice diligence
Measure twice and cut once. Plan thoughtfully, always have someone double-check your work, and take deliberate action.

Spread integrity
Be transparent and honest. Give direct feedback.

Take action
Err on the side of action.No one is above any task; take ownership and get things done.

Think forward
Always think about what you can do today to put the company in the best position in the future.
Remind me to apply later
Apply to Job

First name 

Last name 

Email 

Phone number

Website

Resume
 attach  ATTACH
Cover letter
 attach  ATTACH
 
SUBMIT
Hire, a recruiting app for G Suite
Privacy policy
---
withgoogle
hire app
---
applying splunk senior software eng
https://www.simplyhired.com/job/Zbm2IHsPr9jsUnD16FhXURl5luZCnTEUgbjZh8fqEUOwo9-vcrw8Uw
http://jobs.jobvite.com/splunk/job/o8CO5fwn/apply
https://www.terakeet.com/careers/?p=job%2FoPU85fwG%2FapplyConfirmation&__jvst=Job%20Board&__jvsd=Indeed&nl=1
--

https://www.indeed.com/q-Elixir-or-Erlang-Developer-in-Remote-jobs.html

https://boards.greenhouse.getrake.io/digitaloceancitesremotes/jobs/857064?gh_jid=857064&gh_src=cs3mdi1#confirmation
---
lua, rust
Measurence
Actionable Analytics for the Physical World
penWrt Software Engineer €40k - €60k · 0.0 - 0.2%
Full Time · Remote OK · New York City · Software Engineer · Linux · Lua · Shell Scripting · GNU Make · rust · WiFi (802.11a/b/g/n/ac) and Bluetooth HW · OpenWrt · Mesh Network · Nim

---
Measurence
Actionable Analytics for the Physical World

To apply, email your LinkedIn Url (like: https://www.linkedin.com/in/ikbhal-basha-shaik-2684031b/) AND the link of this job (https://angel.co/measurence/jobs/81088-openwrt-software-engineer) to aprioni@measurence.com cc’ing recruiting-openwrt@measurence.com

--
angel.co
Maidsafe
Secure Access For Everyone

---

Apache Spark Platform Engineer $120k - $180k · 0.5 - 2.0%
Full Time · Remote OK · United States · Software Engineer · Lua · Apache Spark · Go · Apache Beam
Software Engineer £40k - £45k · No equity
Full Time · Remote OK · Troon · Backend Developer · C++ · Distributed Systems · Agile · Rust​ · P2P

---
learn arabic
https://www.youtube.com/watch?v=8ZIwInJfGEo&index=1&list=PL9BD7731DD2FCB7F4

play list
words, picture, voice
---
https://www.madinaharabic.com/vocabulary
https://in.pinterest.com/pin/864409722199294929/?autologin=true

mini picture dictionary
arabic worksheets
---
ruby on rails
blog docker
 capastrino,sempharecI/circleCI
 rspec

 postgres
 redis
 sidekiq

 unicorn
  development &production server
 ---
 earn money by writing tutorial on semaphore: 200$

https://semaphoreci.com/community/tutorials/dockerizing-a-ruby-on-rails-application

server: unicron, puma for ror
ruby version manager: rvm, churby

docker
 loads fast
 no disk space
 contains
   code
   runtime
   system libraries
 isolation
 	cgroups
 uses host kernel api
 ---
 benefits
 cross environment consistency
 expand development team painlessly
 use whatever technology fits best
 	experiments with new languages and framework
 build image once and deploy it many times

 ---
 rails
  4.2.5

 latest : rails 5
 --
 Generating a New Rails Application
We're going to generate a new Rails project without even needing Ruby installed on our work station. We can do this by using the official Rails Docker image.

docker version need>1.9.4
---
# OSX/Windows users will want to remove --­­user "$(id -­u):$(id -­g)"
docker run -it --rm --user "$(id -u):$(id -g)" \
  -v "$PWD":/usr/src/app -w /usr/src/app rails:4 rails new --skip-bundle dummy

# OSX/Windows users will want to remove --­­user "$(id -­u):$(id -­g)"
docker run -it --rm  \
  -v "$PWD":/usr/src/app -w /usr/src/app rails:4 rails new --skip-bundle dummy  

---
https://hub.docker.com/_/rails/
https://store.docker.com/images/ruby
---
Gemfile:

gem 'unicorn', '~> 4.9'
gem 'pg', '~> 0.18.3'
gem 'sidekiq', '~> 4.0.1'
gem 'redis-rails', '~> 4.0.0'
---
DRYing Out the Database Configuration

Change your config/database.yml to look like this:

---

development:
  url: <%= ENV['DATABASE_URL'].gsub('?', '_development?') %>

test:
  url: <%= ENV['DATABASE_URL'].gsub('?', '_test?') %>

staging:
  url: <%= ENV['DATABASE_URL'].gsub('?', '_staging?') %>

production:
  url: <%= ENV['DATABASE_URL'].gsub('?', '_production?') %>

---
DRYing Out the Secrets File

Change your config/secrets.yml to look like this:

---

development: &default
  secret_key_base: <%= ENV['SECRET_TOKEN'] %>

test:
  <<: *default

staging:
  <<: *default

production:
  <<: *default
  --
  Creating the Volumes

In the docker-compose.yml file, we're referencing volumes that do not exist. We can create them by running:

docker volume create --name drkiq-postgres
docker volume create --name drkiq-redis
---
Creating the Docker Compose Configuration File

Next, we will create the docker-compose.yml file and copy the following content into it:

postgres:
  image: postgres:9.4.5
  environment:
    POSTGRES_USER: drkiq
    POSTGRES_PASSWORD: yourpassword
  ports:
    - '5432:5432'
  volumes:
    - drkiq-postgres:/var/lib/postgresql/data

redis:
  image: redis:3.0.5
  ports:
    - '6379:6379'
  volumes:
    - drkiq-redis:/var/lib/redis/data

drkiq:
  build: .
  links:
    - postgres
    - redis
  volumes:
    - .:/drkiq
  ports:
    - '8000:8000'
  env_file:
    - .drkiq.env

sidekiq:
  build: .
  command: bundle exec sidekiq -C config/sidekiq.yml
  links:
    - postgres
    - redis
  volumes:
    - .:/drkiq
  env_file:
    - .drkiq.env    

---

docker volume create --name drkiq-postgres
docker volume create --name drkiq-redis
---
Running Everything

Now it's time to put everything together and start up our stack by running the following:

docker-compose up
---
# OSX/Windows users will want to remove --­­user "$(id -­u):$(id -­g)"
docker­-compose run --­­user "$(id ­-u):$(id -­g)" drkiq rake db:reset
docker­-compose run --­­user "$(id ­-u):$(id -­g)" drkiq rake db:migrate    


# OSX/Windows users will want to remove --­­user "$(id -­u):$(id -­g)"
docker­-compose run  drkiq rake db:reset
docker­-compose run  drkiq rake db:migrate
---
Running Everything, Round 2

Now that our database is initialized, try running the following:

docker-compose up

http://localhost:8000/

---
Right now the source code is on your work station, and that source code is being mounted into the Docker container in real time through a volume.

This means that if you were to edit a file, the changes would take effect instantly, but right now we have no routes or any CSS defined to test this.

Generating a Controller

Run the following command to generate a Pages controller with a home action:

# OSX/Windows users will want to remove --­­user "$(id -­u):$(id -­g)"
docker-­compose run --­­user "$(id -­u):$(id -­g)" drkiq rails g controller Pages home


Adding a New Job

Use the following to add a new job:

# OSX/Windows users will want to remove --­­user "$(id -­u):$(id -­g)"
docker-­compose run --­­user "$(id -­u):$(id -­g)" drkiq rails g job counter

Modifying the Counter Job

Next, replace the perform function to look like this:

def perform(*args)
  21 + 21
end

---
Modifying the Pages Controller

Replace the home action to look like this:

def home
  # We are executing the job on the spot rather than in the background to
  # exercise using Sidekiq in a trivial example.
  #
  # Consult with the Rails documentation to learn more about Active Job:
  # http://edgeguides.rubyonrails.org/active_job_basics.html
  @meaning_of_life = CounterJob.perform_now
end
---
Modifying the Home View

The next step is to replace the app/views/pages/home.html.erb file to look as follows:

<h1>The meaning of life is <%= @meaning_of_life %></h1>

---
Restart the Rails Application

You need to restart the Rails server to pickup new jobs, so hit CTRL+C to stop everything, and then run docker-compose up again.

If you reload the website you should see the changes we made.
---
Semaphore
You can easily set up continuous integration for your Docker projects on Semaphore.

First thing you'll need to do is sign up for a free Semaphore account. Then, you should add your Docker project repository. If your project has a Dockerfile or docker-compose.yml, Semaphore will automatically recommend the platform with Docker support.

Now you can run your images just as you would on your local machine, for example:

  docker build <your-project>
  docker run <your-project>
With your Docker container up and running, you can now run all kinds of tests against it. To learn more about using Docker on Semaphore, you can check out Semaphore's Docker documentation pages.


=-===
docker CI/CD

semaphore.ci
Start testing & deploying with Semaphore
Easy setup. Free for open source. 30-day free trial for private projects.


Pick a username

ikbhal
Your email address

iqbalforall@gmail.com
Create a password

••••••••••
 Create Free Account
or sign up with your GitHub account

Get Started with GitHub
✔Get up and running quickly with 100+ preinstalled tools
✔Run builds 59% - 101% faster than on other CI/CD services
✔Parallelize a large test suite down to minutes
✔Build and deploy microservices with native Docker CI/CD
✔Replace ad-hoc manual deployment with automated pipelines
✔Get quality support straight from our engineers
---
https://semaphoreci.com/docs/docker/setting-up-continuous-integration-for-docker-project.html

https://nickjanetakis.com/

---
Once you have chosen a platform, you can add your container registry host. Semaphore supports:

Docker Hub,
Amazon EC2 Container Registry (ECR),
Google Container Registry (GCR),
Quay.io,
Custom Container Registry.
---
If you don't already have a Semaphore account, sign up for a free account. The free account provides you with unlimited CI service for open-source projects and up to 100 private builds per month.

---
https://semaphoreci.com/product/docker
---
docker-cache
bundle exec inframan docker build
bundle exec inframan docker push
---
ecs deploy..

---
aws cluster
  service name

 ---
 play
 ---
 amazon ec2 container registry(ECR)
 google container registry(GCR)
 custom container registry
 Quay.io
 dockerhub

 ---
 docker run -it --rm  \
  -v "$PWD":/usr/src/app -w /usr/src/app rails:4 rails new --skip-bundle drkiq

 ---
 Get a 1G / 1CPU / 20G docker cluster from CloudHero | Secure Docker Container as a Service For Developers - CloudHero
 'http://cloudhero.io/'

 ---
 But if you combine AWS Free Tier with Docker Hosting – Run Docker Containers in any Cloud - Tutum (which is still free) you have a pretty scalable, fast and flexible solution.
 ---
 Cloudways is a managed cloud and container hosting provide for PHP based sites. Every server on Cloudways comes with ThunderStack(Nginx,Varnish,Apache,PHP-FPM) which helps you improve your site performance and decrease your site load time. Additionally they provide many features on 1-click. On Cloudways, you can enjoy 3 days of free Managed Container Hosting.
 ---
 Try Now - Realtime global deployments - about as simple as it gets. Docker or no docker, and free.

 Containerum offers a free docker cluster (256M RAM，300m CPU，1 TB Traffic，5 GB Volume) for 1 year. No Phone and Credit Card Verify.

Usage example:

https://shui.azurewebsites.net/2...
---
Arukas Docker Hosting Service
ARUKAS CLOUDis
DOCKER HOSTI
https://arukas.io/en/
beta not allwoing to signup
---
https://platform.cloudways.com/signup?utm_source=platform&utm_campaign=November16%20Optin&utm_medium=Signup
was not working
trail expire
---
no free docker hosting
---

$ docker run -it  --rm   -v "$PWD":/usr/src/app -w /usr/src/app rails:4 new --s
kip-bundle drkiq
D:\programfiles\Docker Toolbox\docker.exe: Error response from daemon: oci runti
me error: container_linux.go:295: starting container process caused "exec: \"new
\": executable file not found in $PATH".
time="2017-10-22T09:13:40+05:30" level=error msg="error waiting for container: c
ontext canceled"

---
Learning the Types of Docker Data Volumes
There are three main use cases for Docker data volumes:

To keep data around when a container is removed
To share data between the host filesystem and the Docker container
To share data with other Docker containers

---
ase is a little more advanced, so we won't go into it in this tutorial, but the first two are quite common.

In the first (and simplest) case you just want the data to hang around even if you remove the container, so it's often easiest to let Docker manage where the data gets stored.

Keeping Data Persistent
There's no way to directly create a "data volume" in Docker, so instead we create a data volume container with a volume attached to it. For any other containers that you then want to connect to this data volume container, use the Docker's --volumes-from option to grab the volume from this container and apply them to the current container. This is a bit unusual at first glance, so let's run through a quick example of how we could use this approach to make our byebye file stick around even if the container is removed.

First, create a new data volume container to store our volume:

docker create -v /tmp --name datacontainer ubuntu
This created a container named datacontainer based off of the ubuntu image and in the directory /tmp.

Now, if we run a new Ubuntu container with the --volumes-from flag and run bash again as we did earlier, anything we write to the /tmp directory will get saved to the /tmp volume of our datacontainer container.

First, start the ubuntu image:

docker run -t -i --volumes-from datacontainer ubuntu /bin/bash
The -t command line options calls a terminal from inside the container. The -i flag makes the connection interactive.

At the bash prompt for the ubuntu container, create a file in /tmp:

echo "I'm not going anywhere" > /tmp/hi
Go ahead and type exit to return to your host machine's shell. Now, run the same command again:

docker run -t -i --volumes-from datacontainer ubuntu /bin/bash
This time the hi file is already there:

cat /tmp/hi
---
https://boxboat.com/2016/06/18/docker-data-containers-and-named-volumes/

docker create -v /dbdata --name dbstore training/postgres /bin/true
docker run -d --volumes-from dbstore --name db1 training/postgres

docker volume create --name webapp
---
his is excellent functionality, but how do we take advantage of it? There are three ways to create volumes, with the last being the purpose of this post. We’ve created a short tutorial to show you docker volume create examples, and end with Docker named volumes.
1. Initialize (and mount) at run-time with the -v flag:

$ docker run -P --name web -v /webapp training/webapp python app.py
1
$ docker run -P --name web -v /webapp training/webapp python app.py
This will create a new volume inside a container at /webapp. Anything written to the /webapp directory will be persisted to the host machine, available to the next container that mounts it. But where is the actual volume stored? By using docker inspect, we can find where the it lives:

$ docker inspect -f {{.Mounts}} web
1
$ docker inspect -f {{.Mounts}} web
And you should see something like:

[{d87be9594b1ac6756c6069228e7b991deb1b8803a55dca23b0a3799c30dde05e /var/lib/docker/volumes/d87be9594b1ac6756c6069228e7b991deb1b8803a55dca23b0a3799c30dde05e/_data /webapp local  true }]
1
[{d87be9594b1ac6756c6069228e7b991deb1b8803a55dca23b0a3799c30dde05e /var/lib/docker/volumes/d87be9594b1ac6756c6069228e7b991deb1b8803a55dca23b0a3799c30dde05e/_data /webapp local  true }]
This “anonymous” volume was created at /var/lib/docker/volumes/d87…05e on my host machine. This isn’t exactly the most convenient for organization purposes…
2. Using the VOLUME instruction inside a Dockerfile:

FROM ubuntu:latest

VOLUME /webapp
1
2
3
FROM ubuntu:latest
 
VOLUME /webapp
This has the exact same effect as using the run flag above.
3. Create using the Docker Volume API introduced in Docker 1.9.

$ docker volume create --name webapp
1
$ docker volume create --name webapp
This created a volume that I got to name and didn’t have to attach to anything right away. Seeing the flexibility here? More on this below.
There are other options to mount volumes including specifying host paths to mount directly within a container. Read up on these to become familiar with what’s available.
---
https://docs.docker.com/engine/extend/plugins_volume/

=====
https://hovancik.net/blog/2017/07/02/creating-new-rails-and-vue-js-app-with-docker/

Creating new Rails and Vue.js app with Docker
=---
hovancik.net/blog/

Creating new Rails and Vue.js app with Docker

Posted under ruby rails docker vuejs on Jul 2 2017

·
The most of Rails and Docker tutorials either show how to dockerize your existing app, or how to create new Rails app by installing Rails locally and then adding Docker as second step.

It works but it have always struck me as weird idea: why installing Ruby first? Isn't the point of Docker, at least in part, that I do not need Ruby locally?

I am not that familiar with Docker so I decided to figure this out. Vue.js included, as it's something I want to try out and there's not a lot of stuff about it out there.

The result should be basic example of Vue.js and Rails app running inside Docker container. And for that, I'd like to use webpacker gem. One more thing: no CoffeeScript (which is default for Rails).

I recommend to familiarize yourself with Docker and webpacker, if not already. I am not gonna talk about them a lot.

No local Ruby and Rails

As it turns out, it's not that hard.

All I needed to do is go to the official Docker's Rails example. The document shows how to create new Rails app with PostgreSQL database without need to have Rails or Ruby installed on local machine.

Adding Vue.js to the mix changes steps a bit and that's what I will be writing about.

Docker container

To be able to create new app, we first need to prepare Docker container that can run rails new fancyapp --force --database=postgresql --webpack=vue --skip-coffee command. For that we need to have Rails so feel free to initialize your git repo and create basic Gemfile.

source 'https://rubygems.org'
ruby '2.4.1'
gem 'rails', '~> 5.1', '>= 5.1.1'
Gemfile.lock is empty at this point.

Now let's install other dependencies via Dockerfile.

FROM ruby:2.4.1

RUN apt-get update -qq && apt-get install -y build-essential libpq-dev

# Node.js
RUN curl -sL https://deb.nodesource.com/setup_7.x | bash - \
&& apt-get install -y nodejs

RUN apt-get update && apt-get install -y curl apt-transport-https wget && \
curl -sS https://dl.yarnpkg.com/debian/pubkey.gpg | apt-key add - && \
echo "deb https://dl.yarnpkg.com/debian/ stable main" | tee /etc/apt/sources.list.d/yarn.list && \
apt-get update && apt-get install -y yarn

RUN mkdir /fancyapp
WORKDIR /fancyapp

ADD Gemfile /fancyapp/Gemfile
ADD Gemfile.lock /fancyapp/Gemfile.lock

RUN bundle install

ADD . /fancyapp
This is pretty straightforward: we install PostgreSQL lib, Node.js and yarn. Then we create directory for our fancy app and add Gemfile and Gemfile.lock there. Bundle will install Rails so we can use it to create new app.

Think about your app name here, and name the folder accordingly. Rails app will get name from it.

One last thing is docker-compose.yml. We will use docker-compose to run Docker commands.

version: '3'
services:
  db:
    image: postgres
  web:
    build: .
    command: bundle exec rails s -p 3000 -b '0.0.0.0'
    volumes:
      - .:/fancyapp
    ports:
      - "3000:3000"
    depends_on:
      - db
rails new fancyapp

Now that we are all ready, we need to call docker-compose build. Rails and all deps will get installed, so we can docker-compose run web rails new . --force --database=postgresql --webpack=vue --skip-coffee to create new app.

We do not set application name in rails new command, as we are calling it from inside our app directory. In our case the app will be called fancyapp.

The command mentioned will generate new app with example Vue.js code that we will use later. If you're running on Linux, the newly created files might be owned by root. To be able to work with them, run this:

sudo chown -R $USER:$USER .
Then every time when you create files with docker-compose run ..., do it again.

Do not forget to add ruby '2.4.1' to Gemfile again. It gets removed when using --force.

Now you can run docker-compose build again and docker-compose up. Your app is available at localhost:3000.

Adding Vue.js

The app running right now is ready to run Vue.js code, but our container is not. Let's change that.

To make things easier, we will add new service in our docker-compose running webpacker in development enviroment.

version: '3'
services:
  db:
    image: postgres
  webpacker:
    build: .
    command: bundle exec bin/webpack-dev-server
    volumes:
      - .:/fancyapp
    ports:
      - "8080:8080"
  web:
    build: .
    command: bundle exec rails s -p 3000 -b '0.0.0.0'
    volumes:
      - .:/fancyapp
    ports:
      - "3000:3000"
    depends_on:
      - db
      - webpacker
You might need to run docker-compose run web yarn install to get node packages installed. That's one part I haven't figured out yet.

All that is left now is adding some Vue.js code.

The easiest way is to add simple page via Rails generator: docker-compose run web bundle exec rails g controller home index. We will only change the Index view by adding example Vue.js code generated in the beginning via javascript_pack_tag that will execute code in app/javascript/packs/hello_vue.js.

<h1><%= javascript_pack_tag 'hello_vue' %></h1>
Go up with your container and you should see Hello Vue! in your browser.

Congratz, you have Rails with Vue.js app!

Debugging

If you run into any issue (eg. container wont start), it might be helpful to try to run commands not via docker-compose up, but via docker-compose run .... This way you may get better error output.

One might docker-compose run web bundle exec rails s -p 3000 -b '0.0.0.0' to check whether there is something wrong with Rails starting up.

I had to do that to figure out that pid file of my Rails app was not deleted when container went down.

Next steps

The rails new generated example Vue.js stuff for us, but that's just the start.

As I am not familiar with Vue.js, my next step is doing exactly that. Then I will need to learn more about webpacker. With that knowledge I hope to be able to fully use all the goods that this setup is giving me.

·
Did you enjoy this? Copy-paste the link from the address bar to your favourite social network to share. Subscribe here.

·

·
Jan Hovancik 2014+
software developer - guitar player - poetry lover

·https://hovancik.net/blog/2017/07/02/creating-new-rails-and-vue-js-app-with-docker/
---
http://blog.kontena.io/dockerizing-ruby-application/
---
MENU
Blog
Website
Kontena at Github
SUBSCRIBE
Blog LogoMENU
Dockerizing Ruby Application
08 JUNE 2016
Containers are great and they are gaining more popularity all the time. It’s replacing virtualization by removing hypervisor layer and allowing to run isolated container processes on the shared kernel instead (Image 1). The most important benefit of containers is a start time. While a full virtualized system usually takes minutes to start, containers take seconds, and sometimes even less than a second. With containers there is also a standard how to package application and deliver and deploy it.

Image 1: Moving from virtualization to containerization

Dockerfile
To start putting application into a Docker container, a Dockerfile is needed. It’s like a source code of the Docker image. In Dockerfile are defined all the steps that are required to execute to get application and it's environment up and running.

Docker Image
If Dockerfile is the source code then a Docker image is the compiled version of it. Actually it’s not a single image, but a set of image layers. Image layers are cached so not the whole Docker image is needed to update if Dockerfile will change. The later the change is in Dockerfile the less image layers are required to update.

Ruby Base Images
Every Docker image extends some base image. Typically, a base image contains OS and common libraries and packages. For Ruby developers there are official Ruby base images, that contain specific Ruby versions built-in. The official Ruby base images are:

ruby:version
ruby:onbuild
ruby:slim
ruby:alpine
ruby:version is the de-facto Ruby base image. In addition to Ruby, it contains a large number of extremely common Debian packages.

ruby:onbuild base image is perhaps the easiest one to start with. You need to just extend this image and you are ready to go. It wraps your application automatically into a Docker image on build time. However, it's not recommended for long-term usage within a project due to the lack of control.

ruby:slim is still Debian based but it only contains minimal packages to run Ruby. This is a good choice when you want to use Debian packages and define your environment by yourself.

ruby:alpine is based on Alpine Linux. It’s the smallest ruby base image, but the main caveat is that it does use musl libc instead of glibc and friends, so certain software might run into issues depending on the depth of their libc requirements

Debian based base images may be easier to start with but it comes with the cost of image size (Image 2). It is almost six times bigger than image based on Alpine Linux. Besides the size itself which are faster to transfer, smaller images also make your environment small and efficient. Small images all increase security as you reduce your security footprint size.

Image 2: Sizes of the Official Ruby Images

Of course one option is not to use any of official Ruby base images, but to use other base image instead and build the whole Ruby environment from scratch. Then you have a total control what libraries and packages you want to include in your Docker image.

Docker best practices
When running application in containers there are couple of rules of thumb to follow:

Run one process per container

Decoupling applications into multiple containers makes it much easier to scale horizontally and reuse containers. You can also define Docker to monitor running process of the container and when Docker recognizes the process exits it will restart it automatically

Use a .dockerignore file

To increase the build’s performance, you can exclude files and directories by adding a .dockerignore file to that directory as well. This file supports exclusion patterns similar to .gitignore files

Use Twelve-factor Apps paradigm

If you are running your application on Heroku you are used to use twelve-factor apps paradigm. Docker and containers supports natively this kind of paradigm so if you are not yet familiar with it, you can read more about on http://12factor.net/

Don’t rely on IP addresses

Docker will generate an IP address for each container. However, the IP address will change on every time container is re-created, so you can’t really rely on those addresses. Instead, you have to use some service discovery and DNS.

Example Application
Our example application is a simple Sinatra based application with MongoDB database. You can read all the source codes and Docker files from: https://github.com/kontena/todo-example.

Dockerfile

We will use Alpine Linux based Ruby base image. First, we are adding Gemfile and Gemfile.lock files to Docker image. After that we install Bundler and run bundle install. To reduce the size of the image we will remove build-time dependencies from the Docker image after dependencies are installed. Finally, we will add our application into Docker image and set some permissions and expose a port that the application will listen to. Based on that Docker can route a traffic correctly to container’s port.

FROM ruby:2.3.1-alpine  
ADD Gemfile /app/  
ADD Gemfile.lock /app/  
RUN apk --update add --virtual build-dependencies ruby-dev build-base && \  
    gem install bundler --no-ri --no-rdoc && \
    cd /app ; bundle install --without development test && \
    apk del build-dependencies
ADD . /app  
RUN chown -R nobody:nogroup /app  
USER nobody  
ENV RACK_ENV production  
EXPOSE 9292  
WORKDIR /app  
We can build the Docker image by executing docker build -t todoapp:latest .. This will generate Docker image from the Dockerfile found in the current directory and tag it as todoapp:latest.

Docker-Compose

We can run our application container from Docker image manually with docker run command. However, the better way is to run all application services with Docker Compose. Docker Compose is a tool for defining and running multi-container Docker applications. Application services and their configurations can be defined in docker-compose.yml file:

version: '2’  
services:  
  web:
    image: todoapp:latest
    command: bundle exec puma -p 9292 -e production
    environment:
      - MONGODB_URI=mongodb://mongodb:27017/todo_production
    ports:
      - 9292:9292
    links:
      - mongodb:mongodb
  mongodb:
    image: mongo:3.2
    command: mongod --smallfiles
So, we are defining here one web service that is using our todoapp Docker image. Then we have a MongoDB service from mongo:3.2 image and it’s linked to our web application as mongodb alias.

We can deploy the whole application with docker-compose up command.

So, it’s relatively easy to Dockerize Ruby application and run it locally. When rolling to production things are not that simple anymore. There are couple of things to consider:

How big this app will be? How many users it will serve?
Do you want your application to be infrastructure agnostic or lean heavily on some cloud provider?
How to run databases or save other persistent data?
How to scale the application and handle load balancing?
How do you pass sensitive data to your application and where to store that data?
How the application can be deployed and updated with zero down-time?
You can solve all those things by yourself, but it would be a long and rocky road. Instead, you should choose a container platform that suites for your needs the best.

About Kontena
Kontena is a new open source Docker platform including orchestration, service discovery, overlay networking and all the tools required to run your containerized workloads. Kontena is built to maximize developer happiness. It works on any cloud, it's easy to setup and super simple to use. Give it a try! If you like it, please star it on Github and follow us on Twitter. We hope to see you again!

Image Credits: The Container Guide by Garry Ing

Lauri Nevala
Read more posts by this author.

Helsinki, Finland http://www.kontena.io
Share this post
  

When it comes to container platforms, there isn’t one to rule them all - and that’s OK
In the “Lord of the Rings” trilogy, there was one ring to rule them all. Fortunately, when it comes…
UpCloud & Kontena Partnering to Deliver High Performance Containers and Microservices Platform
We are excited to announce our partnership with UpCloud, the company providing the world's fastest cloud servers with SSD…
Kontena Blog © 2017Proudly published with Ghost
---
https://12factor.net/
---
booom bastard
lets try rspec now
---
https://relishapp.com/rspec/rspec-rails/docs/gettingstarted

Install Rails-3

$ gem install rails -v "~> 3.0.0"

Generate an app

$ rails new example
$ cd example

---
Add rspec-rails to the Gemfile

$ echo 'gem "rspec-rails", :group => [:development, :test]' >> Gemfile

Install the bundle

$ bundle install

Bootstrap RSpec

Generate a scaffold

$ rails generate scaffold Widget name:string
This generates files in the app and spec directories. The files in the
app directory are generated by Rails, and Rails delegates the generation of
the files in the spec directory to RSpec.

Run migrations

$ rake db:migrate && rake db:test:prepare


Run RSpec

$ rake spec

 rspec spec --format documentation

 f all went well, you should see output ending with:

29 examples, 0 failures, 2 pending
This output also includes the following controller spec:

WidgetsController
  GET index
    assigns all widgets as @widgets
  GET show
    assigns the requested widget as @widget
  GET new
    assigns a new widget as @widget
  GET edit
    assigns the requested widget as @widget
  POST create
    with valid params
      creates a new Widget
      assigns a newly created widget as @widget
      redirects to the created widget
    with invalid params
      assigns a newly created but unsaved widget as @widget
      re-renders the 'new' template
  PUT update
    with valid params
      updates the requested widget
      assigns the requested widget as @widget
      redirects to the widget
    with invalid params
      assigns the widget as @widget
      re-renders the 'edit' template
  DELETE destroy
    destroys the requested widget
    redirects to the widgets list

---
https://semaphoreci.com/community/tutorials/how-to-test-rails-models-with-rspec

bin/rails generate model Auction start_date:datetime end_date:datetime title:string description:text
rake db:migrate db:test:prepare

require 'rails_helper'

RSpec.describe Auction, :type => :model do
  it "is valid with valid attributes"
  it "is not valid without a title"
  it "is not valid without a description"
  it "is not valid without a start_date"
  it "is not valid without a end_date"
end

it "is not valid without a title" do
  auction = Auction.new(title: nil)
  expect(auction).to_not be_valid
end

class Auction < ActiveRecord::Base
  validates_presence_of :title
end


class Auction < ActiveRecord::Base
  has_one :buyer, class_name: "User"
  has_one :seller, class_name: "User"

  validates_presence_of :title, :description, :start_date, :end_date
end

describe "Associations" do
  it { should have_one(:buyer) }
  it { should have_one(:seller) }
end


RSpec.describe Bid, :type => :model do
  describe "Associations" do
    it { should belong_to(:bidder) }
    it { should belong_to(:auction) }
  end

  describe "Validations" do
    it { should validate_presence_of(:bidder) }
  end
end

class Bid < ApplicationRecord
  belongs_to :bidder, class_name: "User"

  validates_presence_of :bidder
end

# auction_spec.rb
describe "Associations" do
  it { should belong_to(:buyer) }
  it { should belong_to(:seller) }
  it { should have_many(:bids) }
end

class Auction < ActiveRecord::Base
  belongs_to :buyer, class_name: "User", optional: true # Rails 5!
  belongs_to :seller, class_name: "User"
  has_many :bids

  validates_presence_of :title, :description, :start_date, :end_date
end

https://www.codeschool.com/courses/testing-with-rspec    
rails generate rspec:install