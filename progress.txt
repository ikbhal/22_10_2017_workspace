Target:
4th day/30
----------
1)product building
2)java,springboot, hibernate normal job learning
3)applying remote job
4)ds & algorithms
5)Elm,Erlong, Elixir jobs remote
remoteok, workremotely,hasjob,indeed,naukri,angel.co
6)commit learning to github.com
gathering,tutorial,practicing
7)docker ruby on rails with git
git repo, secret with environment, dockerfile, run locally
8)kafka,couchdb, casandra
go,javaa
9)ruby on rails blog tutorial
10)blogbuiltwith(ror,go,python django,elixir,node.js)
11)elastic search
----------
learn one arabic word every day

1)Applying remote job
Erlong jobs
1)google search Erlong remote jobs
2)update resume in naukri, linkedin with 
Erlong, Elixir,Go
done in naukri
---
weworkremotely site
github jobs
---
https://jobmote.com/jobs/7471-senior-developer-ruby-rails-elm
Our code is a mixture of Ruby, Elm, Javascript, and a dash of Clojure. Additionally, we have a strong interest in functional programming languages like Haskell, OCaml, Elixir, and Idris. We're also using Rails, React, Postgresql, S3, Redis, Memcached, Docker, Nomad, Terraform, and more. While these are the tools we're currently using, you don't need to have previous experience with them. We know that good developers are capable of quickly picking up new languages and tools.

---
functional programming language
Haskell, OCaml, Elixir, Idris

other technologies
Nomad, Terraform, Cloure
---
https://jobs.github.com/positions/6bf2b51c-af87-11e7-8f77-fe95300449e5
http://careers.citrusbyte.com/apply/tPTZOv/Experienced-Backend-Engineer
---
write article on technology
---
Write some code, that will flatten an array of arbitrarily nested arrays of integers into a flat array of integers. e.g. [[1,2,[3]],4] -> [1,2,3,4]. 

Your solution should be a link to a gist on gist.github.com with your implementation.

When writing this code, you can use any language you're comfortable with. The code must be well tested and documented if necessary, and in general please treat the quality of the code as if it was ready to ship to production.

Try to avoid using language defined methods like Ruby's Array#flatten.
---
https://apidock.com/ruby/Array/flatten
---
run ruby online

http://rextester.com/l/ruby_online_compiler
https://repl.it/languages
http://rubyfiddle.com/
---
iterating ruby
--
https://code-maven.com/for-loop-in-ruby
ruby
names = ['Foo', 'Bar', 'Baz']
 
puts names
puts
 
 
names.each { |item|
    puts item
}
puts
 
names.each do |item|
    puts item
end
--
arry.kind_of?(Array)
arr.is_a?

---
https://ruby-doc.org/core-2.2.0/Array.html
---
applied hellosign
---
hacker in residence
startup studio
---
https://www.simplyhired.com/job/7TzKuWs3hWW5_KftQ6UzqFBychl0Zx0dQ-8OPxdpuHlNWwASAqM_hw
---
Telnyx
Elixir Engineer
Product Engineering
Chicago, IL, United States
About Telnyx
Telnyx is building the global telco of the future. We have deployed an international private software-defined network, with multiple tier-1 interconnects, leveraging all major cloud service providers to deliver a voice and messaging solution with carrier-grade reliability. We sell our services in a totally automated fashion, allowing our users to programmatically scale their voice and messaging on-demand.
In addition to providing service and software in major North American and European markets, we are expanding to Asia and are developing a wireless product that will provide licensed spectrum access to our infrastructure.
Telnyx has seventy employees (70% engineers) between our Chicago, IL office, Dublin, Ireland office and remote team. We have actual revenue traction, meaningful sequential monthly growth, and a massive addressable market.

Joining Our Team
At Telnyx, we’re working to globally democratize access to real-time communications over the internet. We’re building a future where voice, messaging, and wireless services can act as building blocks to facilitate high-fidelity, secure, and modern modes of communication.
No matter where you're based, or which team you work on, you’ll be part of a group of people working together to build solutions to mission-critical problems and a company that values the very best ideas. People rely on our products to communicate daily, which means they rely on us to build things with a high degree of resiliency and reliability.

The Role
As an Elixir Engineer at Telnyx, you will deploy groundbreaking applications to solve our customers’ hardest problems. Projects often start with a nebulous question and our Engineers lead the way in developing a solution, from high-level system design and prototyping to application development and data integration. As a Telnyx software engineer, you leverage everything around you: Telnyx products, open source technologies, and anything you and your team can build to drive real impact.
 
You work with users around the globe, where you help our customers by solving their communications challenges. Each mission presents different challenges, from the regulatory environment to the nature of the data to the user population. You will work to accommodate all aspects of an environment to drive real technical outcomes.

In this role, you will:
Build Elixir products for the delivery of mission-critical global communications. These products are latency sensitive and must handle data at scale, all while maintaining an intuitive user experience.
Create tools to automate critical aspects of production systems.

What we value:
Strong engineering background, preferred in fields such as Computer Science, Mathematics, Software Engineering, Physics.
3+ years of professional software development experience with either Ruby or a functional programming language (Clojure, Erlang, etc).
Demonstrated ability to continuously learn, work independently, and make decisions with minimal supervision. You understand that making mistakes means you’re learning, and you actively seek opportunities to grow and develop.
You want to work on software that is changing the world and you're passionate about creating intuitive, scalable products that magnify the analytical capabilities of our users. 
Experience building and operating scalable infrastructure software or distributed systems.
Experience with large-scale production databases and major cloud services.
Familiarity with micro-service architectures.
Highly proficient in a Linux environment. 
Experience with PostgreSQL.
Experience working with message queues (RabbitMQ).
Unit testing (we don’t do TDD, but we like coverage - a lot).

Technologies we use
A variety of languages including Python, Java, Elixir, Scala, Go, Angular, and React.
Open-source technologies like Cassandra, Spark, and ElasticSearch.
Industry-standard build tooling, including Docker, Consul, Jenkins, Ansible, and Github.

Our Guiding Principles
We wrote these principles to be actionable, to inform decision-making and to provide a sense of what’s important and what’s right. We live our values every day. They guide how we hire, train, measure and reward each other.

Stay gritty
Do more with less. We are creative problem solvers that always use constraints to our advantage.

Leverage the experience of others
Avoid unnecessary detours by learning from the mistakes and successes of others. Those who do not learn from history are destined to repeat it.

Improve continually
Perfection is the enemy of progress. Always ask “why.” Think big, start small, collect data, and iterate quickly.

Work together
Seek exponential gains in our work by improving the lives of colleagues and customers.

Practice diligence
Measure twice and cut once. Plan thoughtfully, always have someone double-check your work, and take deliberate action.

Spread integrity
Be transparent and honest. Give direct feedback.

Take action
Err on the side of action.No one is above any task; take ownership and get things done.

Think forward
Always think about what you can do today to put the company in the best position in the future.
Remind me to apply later
Apply to Job

First name 

Last name 

Email 

Phone number

Website

Resume
 attach  ATTACH
Cover letter
 attach  ATTACH
 
SUBMIT
Hire, a recruiting app for G Suite
Privacy policy
---
withgoogle
hire app
---
applying splunk senior software eng
https://www.simplyhired.com/job/Zbm2IHsPr9jsUnD16FhXURl5luZCnTEUgbjZh8fqEUOwo9-vcrw8Uw
http://jobs.jobvite.com/splunk/job/o8CO5fwn/apply
https://www.terakeet.com/careers/?p=job%2FoPU85fwG%2FapplyConfirmation&__jvst=Job%20Board&__jvsd=Indeed&nl=1
--

https://www.indeed.com/q-Elixir-or-Erlang-Developer-in-Remote-jobs.html

https://boards.greenhouse.getrake.io/digitaloceancitesremotes/jobs/857064?gh_jid=857064&gh_src=cs3mdi1#confirmation
---
lua, rust
Measurence
Actionable Analytics for the Physical World
penWrt Software Engineer €40k - €60k · 0.0 - 0.2%
Full Time · Remote OK · New York City · Software Engineer · Linux · Lua · Shell Scripting · GNU Make · rust · WiFi (802.11a/b/g/n/ac) and Bluetooth HW · OpenWrt · Mesh Network · Nim

---
Measurence
Actionable Analytics for the Physical World

To apply, email your LinkedIn Url (like: https://www.linkedin.com/in/ikbhal-basha-shaik-2684031b/) AND the link of this job (https://angel.co/measurence/jobs/81088-openwrt-software-engineer) to aprioni@measurence.com cc’ing recruiting-openwrt@measurence.com

--
angel.co
Maidsafe
Secure Access For Everyone

---

Apache Spark Platform Engineer $120k - $180k · 0.5 - 2.0%
Full Time · Remote OK · United States · Software Engineer · Lua · Apache Spark · Go · Apache Beam
Software Engineer £40k - £45k · No equity
Full Time · Remote OK · Troon · Backend Developer · C++ · Distributed Systems · Agile · Rust​ · P2P

---
learn arabic
https://www.youtube.com/watch?v=8ZIwInJfGEo&index=1&list=PL9BD7731DD2FCB7F4

play list
words, picture, voice
---
https://www.madinaharabic.com/vocabulary
https://in.pinterest.com/pin/864409722199294929/?autologin=true

mini picture dictionary
arabic worksheets
---
ruby on rails
blog docker
 capastrino,sempharecI/circleCI
 rspec

 postgres
 redis
 sidekiq

 unicorn
  development &production server
 ---
 earn money by writing tutorial on semaphore: 200$

https://semaphoreci.com/community/tutorials/dockerizing-a-ruby-on-rails-application

server: unicron, puma for ror
ruby version manager: rvm, churby

docker
 loads fast
 no disk space
 contains
   code
   runtime
   system libraries
 isolation
 	cgroups
 uses host kernel api
 ---
 benefits
 cross environment consistency
 expand development team painlessly
 use whatever technology fits best
 	experiments with new languages and framework
 build image once and deploy it many times

 ---
 rails
  4.2.5

 latest : rails 5
 --
 Generating a New Rails Application
We're going to generate a new Rails project without even needing Ruby installed on our work station. We can do this by using the official Rails Docker image.

docker version need>1.9.4
---
# OSX/Windows users will want to remove --­­user "$(id -­u):$(id -­g)"
docker run -it --rm --user "$(id -u):$(id -g)" \
  -v "$PWD":/usr/src/app -w /usr/src/app rails:4 rails new --skip-bundle dummy

# OSX/Windows users will want to remove --­­user "$(id -­u):$(id -­g)"
docker run -it --rm  \
  -v "$PWD":/usr/src/app -w /usr/src/app rails:4 rails new --skip-bundle dummy  

---
https://hub.docker.com/_/rails/
https://store.docker.com/images/ruby
---
Gemfile:

gem 'unicorn', '~> 4.9'
gem 'pg', '~> 0.18.3'
gem 'sidekiq', '~> 4.0.1'
gem 'redis-rails', '~> 4.0.0'
---
DRYing Out the Database Configuration

Change your config/database.yml to look like this:

---

development:
  url: <%= ENV['DATABASE_URL'].gsub('?', '_development?') %>

test:
  url: <%= ENV['DATABASE_URL'].gsub('?', '_test?') %>

staging:
  url: <%= ENV['DATABASE_URL'].gsub('?', '_staging?') %>

production:
  url: <%= ENV['DATABASE_URL'].gsub('?', '_production?') %>

---
DRYing Out the Secrets File

Change your config/secrets.yml to look like this:

---

development: &default
  secret_key_base: <%= ENV['SECRET_TOKEN'] %>

test:
  <<: *default

staging:
  <<: *default

production:
  <<: *default
  --
  Creating the Volumes

In the docker-compose.yml file, we're referencing volumes that do not exist. We can create them by running:

docker volume create --name drkiq-postgres
docker volume create --name drkiq-redis
---
Creating the Docker Compose Configuration File

Next, we will create the docker-compose.yml file and copy the following content into it:

postgres:
  image: postgres:9.4.5
  environment:
    POSTGRES_USER: drkiq
    POSTGRES_PASSWORD: yourpassword
  ports:
    - '5432:5432'
  volumes:
    - drkiq-postgres:/var/lib/postgresql/data

redis:
  image: redis:3.0.5
  ports:
    - '6379:6379'
  volumes:
    - drkiq-redis:/var/lib/redis/data

drkiq:
  build: .
  links:
    - postgres
    - redis
  volumes:
    - .:/drkiq
  ports:
    - '8000:8000'
  env_file:
    - .drkiq.env

sidekiq:
  build: .
  command: bundle exec sidekiq -C config/sidekiq.yml
  links:
    - postgres
    - redis
  volumes:
    - .:/drkiq
  env_file:
    - .drkiq.env    

---

docker volume create --name drkiq-postgres
docker volume create --name drkiq-redis
---
Running Everything

Now it's time to put everything together and start up our stack by running the following:

docker-compose up
---
# OSX/Windows users will want to remove --­­user "$(id -­u):$(id -­g)"
docker­-compose run --­­user "$(id ­-u):$(id -­g)" drkiq rake db:reset
docker­-compose run --­­user "$(id ­-u):$(id -­g)" drkiq rake db:migrate    


# OSX/Windows users will want to remove --­­user "$(id -­u):$(id -­g)"
docker­-compose run  drkiq rake db:reset
docker­-compose run  drkiq rake db:migrate
---
Running Everything, Round 2

Now that our database is initialized, try running the following:

docker-compose up

http://localhost:8000/

---
Right now the source code is on your work station, and that source code is being mounted into the Docker container in real time through a volume.

This means that if you were to edit a file, the changes would take effect instantly, but right now we have no routes or any CSS defined to test this.

Generating a Controller

Run the following command to generate a Pages controller with a home action:

# OSX/Windows users will want to remove --­­user "$(id -­u):$(id -­g)"
docker-­compose run --­­user "$(id -­u):$(id -­g)" drkiq rails g controller Pages home


Adding a New Job

Use the following to add a new job:

# OSX/Windows users will want to remove --­­user "$(id -­u):$(id -­g)"
docker-­compose run --­­user "$(id -­u):$(id -­g)" drkiq rails g job counter

Modifying the Counter Job

Next, replace the perform function to look like this:

def perform(*args)
  21 + 21
end

---
Modifying the Pages Controller

Replace the home action to look like this:

def home
  # We are executing the job on the spot rather than in the background to
  # exercise using Sidekiq in a trivial example.
  #
  # Consult with the Rails documentation to learn more about Active Job:
  # http://edgeguides.rubyonrails.org/active_job_basics.html
  @meaning_of_life = CounterJob.perform_now
end
---
Modifying the Home View

The next step is to replace the app/views/pages/home.html.erb file to look as follows:

<h1>The meaning of life is <%= @meaning_of_life %></h1>

---
Restart the Rails Application

You need to restart the Rails server to pickup new jobs, so hit CTRL+C to stop everything, and then run docker-compose up again.

If you reload the website you should see the changes we made.
---
Semaphore
You can easily set up continuous integration for your Docker projects on Semaphore.

First thing you'll need to do is sign up for a free Semaphore account. Then, you should add your Docker project repository. If your project has a Dockerfile or docker-compose.yml, Semaphore will automatically recommend the platform with Docker support.

Now you can run your images just as you would on your local machine, for example:

  docker build <your-project>
  docker run <your-project>
With your Docker container up and running, you can now run all kinds of tests against it. To learn more about using Docker on Semaphore, you can check out Semaphore's Docker documentation pages.


=-===
docker CI/CD

semaphore.ci
Start testing & deploying with Semaphore
Easy setup. Free for open source. 30-day free trial for private projects.


Pick a username

ikbhal
Your email address

iqbalforall@gmail.com
Create a password

••••••••••
 Create Free Account
or sign up with your GitHub account

Get Started with GitHub
✔Get up and running quickly with 100+ preinstalled tools
✔Run builds 59% - 101% faster than on other CI/CD services
✔Parallelize a large test suite down to minutes
✔Build and deploy microservices with native Docker CI/CD
✔Replace ad-hoc manual deployment with automated pipelines
✔Get quality support straight from our engineers
---
https://semaphoreci.com/docs/docker/setting-up-continuous-integration-for-docker-project.html

https://nickjanetakis.com/

---
Once you have chosen a platform, you can add your container registry host. Semaphore supports:

Docker Hub,
Amazon EC2 Container Registry (ECR),
Google Container Registry (GCR),
Quay.io,
Custom Container Registry.
---
If you don't already have a Semaphore account, sign up for a free account. The free account provides you with unlimited CI service for open-source projects and up to 100 private builds per month.

---
https://semaphoreci.com/product/docker
---
docker-cache
bundle exec inframan docker build
bundle exec inframan docker push
---
ecs deploy..

---
aws cluster
  service name

 ---
 play
 ---
 amazon ec2 container registry(ECR)
 google container registry(GCR)
 custom container registry
 Quay.io
 dockerhub

 ---
 docker run -it --rm  \
  -v "$PWD":/usr/src/app -w /usr/src/app rails:4 rails new --skip-bundle drkiq

 ---
 Get a 1G / 1CPU / 20G docker cluster from CloudHero | Secure Docker Container as a Service For Developers - CloudHero
 'http://cloudhero.io/'

 ---
 But if you combine AWS Free Tier with Docker Hosting – Run Docker Containers in any Cloud - Tutum (which is still free) you have a pretty scalable, fast and flexible solution.
 ---
 Cloudways is a managed cloud and container hosting provide for PHP based sites. Every server on Cloudways comes with ThunderStack(Nginx,Varnish,Apache,PHP-FPM) which helps you improve your site performance and decrease your site load time. Additionally they provide many features on 1-click. On Cloudways, you can enjoy 3 days of free Managed Container Hosting.
 ---
 Try Now - Realtime global deployments - about as simple as it gets. Docker or no docker, and free.

 Containerum offers a free docker cluster (256M RAM，300m CPU，1 TB Traffic，5 GB Volume) for 1 year. No Phone and Credit Card Verify.

Usage example:

https://shui.azurewebsites.net/2...
---
Arukas Docker Hosting Service
ARUKAS CLOUDis
DOCKER HOSTI
https://arukas.io/en/
beta not allwoing to signup
---
https://platform.cloudways.com/signup?utm_source=platform&utm_campaign=November16%20Optin&utm_medium=Signup
was not working
trail expire
---
no free docker hosting
---

$ docker run -it  --rm   -v "$PWD":/usr/src/app -w /usr/src/app rails:4 new --s
kip-bundle drkiq
D:\programfiles\Docker Toolbox\docker.exe: Error response from daemon: oci runti
me error: container_linux.go:295: starting container process caused "exec: \"new
\": executable file not found in $PATH".
time="2017-10-22T09:13:40+05:30" level=error msg="error waiting for container: c
ontext canceled"

---
Learning the Types of Docker Data Volumes
There are three main use cases for Docker data volumes:

To keep data around when a container is removed
To share data between the host filesystem and the Docker container
To share data with other Docker containers

---
ase is a little more advanced, so we won't go into it in this tutorial, but the first two are quite common.

In the first (and simplest) case you just want the data to hang around even if you remove the container, so it's often easiest to let Docker manage where the data gets stored.

Keeping Data Persistent
There's no way to directly create a "data volume" in Docker, so instead we create a data volume container with a volume attached to it. For any other containers that you then want to connect to this data volume container, use the Docker's --volumes-from option to grab the volume from this container and apply them to the current container. This is a bit unusual at first glance, so let's run through a quick example of how we could use this approach to make our byebye file stick around even if the container is removed.

First, create a new data volume container to store our volume:

docker create -v /tmp --name datacontainer ubuntu
This created a container named datacontainer based off of the ubuntu image and in the directory /tmp.

Now, if we run a new Ubuntu container with the --volumes-from flag and run bash again as we did earlier, anything we write to the /tmp directory will get saved to the /tmp volume of our datacontainer container.

First, start the ubuntu image:

docker run -t -i --volumes-from datacontainer ubuntu /bin/bash
The -t command line options calls a terminal from inside the container. The -i flag makes the connection interactive.

At the bash prompt for the ubuntu container, create a file in /tmp:

echo "I'm not going anywhere" > /tmp/hi
Go ahead and type exit to return to your host machine's shell. Now, run the same command again:

docker run -t -i --volumes-from datacontainer ubuntu /bin/bash
This time the hi file is already there:

cat /tmp/hi
---
https://boxboat.com/2016/06/18/docker-data-containers-and-named-volumes/

docker create -v /dbdata --name dbstore training/postgres /bin/true
docker run -d --volumes-from dbstore --name db1 training/postgres

docker volume create --name webapp
---
his is excellent functionality, but how do we take advantage of it? There are three ways to create volumes, with the last being the purpose of this post. We’ve created a short tutorial to show you docker volume create examples, and end with Docker named volumes.
1. Initialize (and mount) at run-time with the -v flag:

$ docker run -P --name web -v /webapp training/webapp python app.py
1
$ docker run -P --name web -v /webapp training/webapp python app.py
This will create a new volume inside a container at /webapp. Anything written to the /webapp directory will be persisted to the host machine, available to the next container that mounts it. But where is the actual volume stored? By using docker inspect, we can find where the it lives:

$ docker inspect -f {{.Mounts}} web
1
$ docker inspect -f {{.Mounts}} web
And you should see something like:

[{d87be9594b1ac6756c6069228e7b991deb1b8803a55dca23b0a3799c30dde05e /var/lib/docker/volumes/d87be9594b1ac6756c6069228e7b991deb1b8803a55dca23b0a3799c30dde05e/_data /webapp local  true }]
1
[{d87be9594b1ac6756c6069228e7b991deb1b8803a55dca23b0a3799c30dde05e /var/lib/docker/volumes/d87be9594b1ac6756c6069228e7b991deb1b8803a55dca23b0a3799c30dde05e/_data /webapp local  true }]
This “anonymous” volume was created at /var/lib/docker/volumes/d87…05e on my host machine. This isn’t exactly the most convenient for organization purposes…
2. Using the VOLUME instruction inside a Dockerfile:

FROM ubuntu:latest

VOLUME /webapp
1
2
3
FROM ubuntu:latest
 
VOLUME /webapp
This has the exact same effect as using the run flag above.
3. Create using the Docker Volume API introduced in Docker 1.9.

$ docker volume create --name webapp
1
$ docker volume create --name webapp
This created a volume that I got to name and didn’t have to attach to anything right away. Seeing the flexibility here? More on this below.
There are other options to mount volumes including specifying host paths to mount directly within a container. Read up on these to become familiar with what’s available.
---
https://docs.docker.com/engine/extend/plugins_volume/